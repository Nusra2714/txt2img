{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nusra2714/txt2img/blob/main/notebooks/text2im.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSWoBxJbY9zF",
        "outputId": "7f1e16d5-324a-434e-9cdc-c6c6fcbbb62b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/glide-text2im\n",
            "  Cloning https://github.com/openai/glide-text2im to /tmp/pip-req-build-uaout0y2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/glide-text2im /tmp/pip-req-build-uaout0y2\n",
            "  Resolved https://github.com/openai/glide-text2im to commit 69b530740eb6cef69442d6180579ef5ba9ef063e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from glide-text2im==0.0.0) (11.1.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from glide-text2im==0.0.0) (25.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from glide-text2im==0.0.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from glide-text2im==0.0.0) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from glide-text2im==0.0.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from glide-text2im==0.0.0) (4.67.1)\n",
            "Collecting ftfy (from glide-text2im==0.0.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from glide-text2im==0.0.0) (2024.11.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from glide-text2im==0.0.0) (1.26.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->glide-text2im==0.0.0) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->glide-text2im==0.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->glide-text2im==0.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->glide-text2im==0.0.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->glide-text2im==0.0.0) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->glide-text2im==0.0.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->glide-text2im==0.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->glide-text2im==0.0.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->glide-text2im==0.0.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->glide-text2im==0.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->glide-text2im==0.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->glide-text2im==0.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->glide-text2im==0.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->glide-text2im==0.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->glide-text2im==0.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->glide-text2im==0.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->glide-text2im==0.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->glide-text2im==0.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->glide-text2im==0.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->glide-text2im==0.0.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->glide-text2im==0.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->glide-text2im==0.0.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->glide-text2im==0.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->glide-text2im==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->glide-text2im==0.0.0) (3.0.2)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: glide-text2im\n",
            "  Building wheel for glide-text2im (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glide-text2im: filename=glide_text2im-0.0.0-py3-none-any.whl size=1953624 sha256=5d0670b948db6879e565bb822b628fea4aa17272748c1564785195ecf06268a1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bd3equm2/wheels/bd/72/ac/ea4ffada8b512103257089f380fbe343724a96fd6f1242d5d3\n",
            "Successfully built glide-text2im\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, glide-text2im\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n"
          ]
        }
      ],
      "source": [
        "# Run this line in Colab to install the package if it is\n",
        "# not already installed.\n",
        "!pip install git+https://github.com/openai/glide-text2im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClvCAYkTY9zP"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import torch as th\n",
        "\n",
        "from glide_text2im.download import load_checkpoint\n",
        "from glide_text2im.model_creation import (\n",
        "    create_model_and_diffusion,\n",
        "    model_and_diffusion_defaults,\n",
        "    model_and_diffusion_defaults_upsampler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea2sV7gMY9zR"
      },
      "outputs": [],
      "source": [
        "# This notebook supports both CPU and GPU.\n",
        "# On CPU, generating one sample may take on the order of 20 minutes.\n",
        "# On a GPU, it should be under a minute.\n",
        "\n",
        "has_cuda = th.cuda.is_available()\n",
        "device = th.device('cpu' if not has_cuda else 'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZbT9XzrY9zS"
      },
      "outputs": [],
      "source": [
        "# Create base model.\n",
        "options = model_and_diffusion_defaults()\n",
        "options['use_fp16'] = has_cuda\n",
        "options['timestep_respacing'] = '100' # use 100 diffusion steps for fast sampling\n",
        "model, diffusion = create_model_and_diffusion(**options)\n",
        "model.eval()\n",
        "if has_cuda:\n",
        "    model.convert_to_fp16()\n",
        "model.to(device)\n",
        "model.load_state_dict(load_checkpoint('base', device))\n",
        "print('total base parameters', sum(x.numel() for x in model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6nhOrdNY9zT"
      },
      "outputs": [],
      "source": [
        "# Create upsampler model.\n",
        "options_up = model_and_diffusion_defaults_upsampler()\n",
        "options_up['use_fp16'] = has_cuda\n",
        "options_up['timestep_respacing'] = 'fast27' # use 27 diffusion steps for very fast sampling\n",
        "model_up, diffusion_up = create_model_and_diffusion(**options_up)\n",
        "model_up.eval()\n",
        "if has_cuda:\n",
        "    model_up.convert_to_fp16()\n",
        "model_up.to(device)\n",
        "model_up.load_state_dict(load_checkpoint('upsample', device))\n",
        "print('total upsampler parameters', sum(x.numel() for x in model_up.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzrpevvhY9zU"
      },
      "outputs": [],
      "source": [
        "def show_images(batch: th.Tensor):\n",
        "    \"\"\" Display a batch of images inline. \"\"\"\n",
        "    scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
        "    reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
        "    display(Image.fromarray(reshaped.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIqKlHasY9zW"
      },
      "outputs": [],
      "source": [
        "# Sampling parameters\n",
        "prompt = \"an oil painting of a corgi\"\n",
        "batch_size = 1\n",
        "guidance_scale = 3.0\n",
        "\n",
        "# Tune this parameter to control the sharpness of 256x256 images.\n",
        "# A value of 1.0 is sharper, but sometimes results in grainy artifacts.\n",
        "upsample_temp = 0.997"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMtPW_2UY9zX"
      },
      "outputs": [],
      "source": [
        "##############################\n",
        "# Sample from the base model #\n",
        "##############################\n",
        "\n",
        "# Create the text tokens to feed to the model.\n",
        "tokens = model.tokenizer.encode(prompt)\n",
        "tokens, mask = model.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options['text_ctx']\n",
        ")\n",
        "\n",
        "# Create the classifier-free guidance tokens (empty)\n",
        "full_batch_size = batch_size * 2\n",
        "uncond_tokens, uncond_mask = model.tokenizer.padded_tokens_and_mask(\n",
        "    [], options['text_ctx']\n",
        ")\n",
        "\n",
        "# Pack the tokens together into model kwargs.\n",
        "model_kwargs = dict(\n",
        "    tokens=th.tensor(\n",
        "        [tokens] * batch_size + [uncond_tokens] * batch_size, device=device\n",
        "    ),\n",
        "    mask=th.tensor(\n",
        "        [mask] * batch_size + [uncond_mask] * batch_size,\n",
        "        dtype=th.bool,\n",
        "        device=device,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Create a classifier-free guidance sampling function\n",
        "def model_fn(x_t, ts, **kwargs):\n",
        "    half = x_t[: len(x_t) // 2]\n",
        "    combined = th.cat([half, half], dim=0)\n",
        "    model_out = model(combined, ts, **kwargs)\n",
        "    eps, rest = model_out[:, :3], model_out[:, 3:]\n",
        "    cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim=0)\n",
        "    half_eps = uncond_eps + guidance_scale * (cond_eps - uncond_eps)\n",
        "    eps = th.cat([half_eps, half_eps], dim=0)\n",
        "    return th.cat([eps, rest], dim=1)\n",
        "\n",
        "# Sample from the base model.\n",
        "model.del_cache()\n",
        "samples = diffusion.p_sample_loop(\n",
        "    model_fn,\n",
        "    (full_batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=None,\n",
        ")[:batch_size]\n",
        "model.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHIk2768Y9zY"
      },
      "outputs": [],
      "source": [
        "##############################\n",
        "# Upsample the 64x64 samples #\n",
        "##############################\n",
        "\n",
        "tokens = model_up.tokenizer.encode(prompt)\n",
        "tokens, mask = model_up.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options_up['text_ctx']\n",
        ")\n",
        "\n",
        "# Create the model conditioning dict.\n",
        "model_kwargs = dict(\n",
        "    # Low-res image to upsample.\n",
        "    low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
        "\n",
        "    # Text tokens\n",
        "    tokens=th.tensor(\n",
        "        [tokens] * batch_size, device=device\n",
        "    ),\n",
        "    mask=th.tensor(\n",
        "        [mask] * batch_size,\n",
        "        dtype=th.bool,\n",
        "        device=device,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Sample from the base model.\n",
        "model_up.del_cache()\n",
        "up_shape = (batch_size, 3, options_up[\"image_size\"], options_up[\"image_size\"])\n",
        "up_samples = diffusion_up.ddim_sample_loop(\n",
        "    model_up,\n",
        "    up_shape,\n",
        "    noise=th.randn(up_shape, device=device) * upsample_temp,\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=None,\n",
        ")[:batch_size]\n",
        "model_up.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(up_samples)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e7d6e62d90e7e85f9a0faa7f0b1d576302d7ae6108e9fe361594f8e1c8b05781"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}